# 💫 Web Scraping Journey: 30天爬虫成长计划

从静态数据到动态渲染的爬虫进化之路 | 每天解锁新技能，构建完整知识体系

## 🎯 项目概述

大家应该都听过或者玩过横版闯关游戏吧？击倒无数怪物，重来千百次，历经千辛万苦，战胜最后的大BOSS的感觉很不错吧o(￣▽￣)o <br>

为了让我们的爬虫学习之旅更加有趣，这次我们也会像升级打怪一样，挑战重重关卡，层层递进，由浅入深地畅游在爬虫世界。<br>

这个仓库记录了我系统学习网络爬虫技术的完整过程。<br>

通过30天精心设计的任务，我们将逐步掌握：

🏆 从基础网页解析到动态渲染处理的全流程技能

🛡️应对各种反爬机制的实际解决方案

📊 数据清洗、存储和可视化的专业方法

🧩 逆向工程和分布式爬虫的高级应用

每个任务都针对真实网站设计，确保学到的技能可以直接应用于实际项目。

## 📂 仓库结构
 ```
.
├── 📁 0_Bootcamp/          # 基础训练区（第1-7天）
│   └── Day1_HTML基础解析/
├── 📁 1_Static_Expert/     # 静态爬虫进阶（第8-14天）
│   └── Day8_请求头伪装/
├── 📁 2_Dynamic_Dungeons/   # 动态页面处理（第15-21天）
│   └── Day15_Selenium基础/
├── 📁 3_Boss_Battles/     # 高级技术区（第22-30天）
│   └── Day22_JS逆向工程/
├── 📜 Adventure_Log.md  # 学习进度追踪
├── 📜 Survival_Guide.md     # 技术要点手册
└── 📜 README_CN.md            # 项目说明
 ```

## 🚀 每日任务系统
每个任务都是一个完整的学习单元，例如：
 ```
Day1_HTML基础解析/
├── task.md            # 任务说明与技术笔记
├── scraper.py         # 爬虫主代码
├── requirements.txt   # 依赖清单
├── output/            # 输出文件
└── knowledge_base.md  # 扩展知识库
 ```

## ⚙️ 技术体系
核心技术栈：

* 数据获取：Requests, HTTPX

* 页面解析：BeautifulSoup, lxml, PyQuery

* 动态渲染：Selenium, Playwright

* 数据管理：Pandas, SQLAlchemy

* 高级应用：Scrapy, Mitmproxy

# 🌟 加入学习
```
# 克隆本仓库
git clone https://github.com/yourname/web-scraping-journey.git

# 进入Day1任务目录
cd 0_Bootcamp/Day1_HTML基础解析

# 安装依赖
pip install -r requirements.txt

# 运行爬虫
python scraper.py
```

# 📚 学习资源
* [BeautifulSoup官方文档](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)
* [Scrapy学习指南](https://docs.scrapy.org/en/latest/intro/tutorial.html)
* 未完待续...

维护者：Jade Cao <br>
最后更新：2025年8月13日

"代码是最好的学习笔记，提交记录是成长的见证。
每天进步一点点，30天后你会惊讶于自己的蜕变。
—— 与所有学习者共勉

感谢你的阅读！欢迎任何反馈哦 o(=•ェ•=)m
